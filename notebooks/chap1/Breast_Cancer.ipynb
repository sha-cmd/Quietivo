{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10776cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import get_data_home\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7989a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72331a36",
   "metadata": {},
   "source": [
    "We can use a threshold to select feature that increase the variance and decrease the biais. This filtering improve the risk of overfitting, we may stay aware of that possibility during the evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a29ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X_sel = sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbef7d",
   "metadata": {},
   "source": [
    "The feature selection kept 11 columns on 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e548600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 11), (569, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sel.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb21e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50812d",
   "metadata": {},
   "source": [
    "We can split the data in train and test samples, to evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa723f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X_sel, y)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ec5c1",
   "metadata": {},
   "source": [
    "For a quick overview, now we can test many classifiers and compare time for fitting and some metrics of evaluation for each modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e66152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe669489",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVC\": SVC,\n",
    "    \"Linear\": LogisticRegression,\n",
    "    \"SGDC\": SGDClassifier,\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"GaussianProcessClassifier\": GaussianProcessClassifier,\n",
    "    \"GaussianNB\": GaussianNB,\n",
    "    \"MLPClassifier\": MLPClassifier\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da712976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC : 0.013014554977416992 seconds, accuracy : 0.9122807017543859\n",
      "confusion matrix : \n",
      "[[34  8]\n",
      " [ 2 70]]\n",
      "\n",
      "Linear : 0.04766225814819336 seconds, accuracy : 0.9473684210526315\n",
      "confusion matrix : \n",
      "[[39  3]\n",
      " [ 3 69]]\n",
      "\n",
      "SGDC : 0.00325775146484375 seconds, accuracy : 0.8859649122807017\n",
      "confusion matrix : \n",
      "[[38  4]\n",
      " [ 9 63]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/Documents/BackUp/Special/Projets/Code_IIA/Quietivo/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier : 0.0003905296325683594 seconds, accuracy : 0.9122807017543859\n",
      "confusion matrix : \n",
      "[[37  5]\n",
      " [ 5 67]]\n",
      "\n",
      "RandomForestClassifier : 0.15900969505310059 seconds, accuracy : 0.956140350877193\n",
      "confusion matrix : \n",
      "[[40  2]\n",
      " [ 3 69]]\n",
      "\n",
      "GaussianProcessClassifier : 0.15772080421447754 seconds, accuracy : 0.8771929824561403\n",
      "confusion matrix : \n",
      "[[37  5]\n",
      " [ 9 63]]\n",
      "\n",
      "GaussianNB : 0.0011992454528808594 seconds, accuracy : 0.9210526315789473\n",
      "confusion matrix : \n",
      "[[38  4]\n",
      " [ 5 67]]\n",
      "\n",
      "MLPClassifier : 0.17904996871948242 seconds, accuracy : 0.9035087719298246\n",
      "confusion matrix : \n",
      "[[38  4]\n",
      " [ 7 65]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    start = time.time()\n",
    "    clf = model().fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    y_pred = clf.predict(X=X_test)\n",
    "    y_true = y_test\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"{name} : {end - start} seconds, accuracy : {acc}\\nconfusion matrix : \\n{cm}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fe526",
   "metadata": {},
   "source": [
    "RandomForest and LogisticRegression are two classifiers that predict our data very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ceefb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Quietivo",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
